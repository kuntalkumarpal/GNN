{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Node Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root=\"data/Cora\", name=\"Cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708]),\n",
       " ['x', 'edge_index', 'y', 'train_mask', 'val_mask', 'test_mask'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0], dataset[0].keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "         [ 633, 1862, 2582,  ...,  598, 1473, 2706]]),\n",
       " 2708,\n",
       " 10556,\n",
       " 1433,\n",
       " False,\n",
       " False,\n",
       " False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_classes, dataset[0].x, dataset[0].edge_index, dataset[0].num_nodes, dataset[0].num_edges, dataset[0].num_node_features, dataset[0].contains_isolated_nodes(), dataset[0].contains_self_loops(), dataset[0].is_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 500, 1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].train_mask.sum().item(),dataset[0].val_mask.sum().item(),dataset[0].test_mask.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  Loss: tensor(1.9459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 1  Loss: tensor(1.8367, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 2  Loss: tensor(1.7206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 3  Loss: tensor(1.5555, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 4  Loss: tensor(1.4280, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 5  Loss: tensor(1.3028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 6  Loss: tensor(1.1804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 7  Loss: tensor(1.0678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 8  Loss: tensor(0.9721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 9  Loss: tensor(0.8679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 10  Loss: tensor(0.7796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 11  Loss: tensor(0.7012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 12  Loss: tensor(0.6563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 13  Loss: tensor(0.5756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 14  Loss: tensor(0.5335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 15  Loss: tensor(0.4388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 16  Loss: tensor(0.4096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 17  Loss: tensor(0.3476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 18  Loss: tensor(0.3106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 19  Loss: tensor(0.3312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 20  Loss: tensor(0.2768, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(300):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    if epoch<=20:\n",
    "        print(\"Epoch:\",epoch,\" Loss:\",loss)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8080\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / int(data.test_mask.sum())\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching (Minibatching do not need padding as giant Diagonal matrix is created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_scatter import scatter_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ls11-www.cs.tu-dortmund.de/people/morris/graphkerneldatasets/ENZYMES.zip\n",
      "Extracting data/ENZYMES/ENZYMES.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = TUDataset(root='data', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[925], edge_index=[2, 3666], x=[925, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1091], edge_index=[2, 4366], x=[1091, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1109], edge_index=[2, 4322], x=[1109, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[954], edge_index=[2, 3734], x=[954, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1176], edge_index=[2, 4502], x=[1176, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1102], edge_index=[2, 4066], x=[1102, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1072], edge_index=[2, 3960], x=[1072, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1079], edge_index=[2, 3906], x=[1079, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1024], edge_index=[2, 3866], x=[1024, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[977], edge_index=[2, 3390], x=[977, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1095], edge_index=[2, 4138], x=[1095, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[857], edge_index=[2, 3404], x=[857, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1227], edge_index=[2, 4634], x=[1227, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[997], edge_index=[2, 3770], x=[997, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[995], edge_index=[2, 3804], x=[995, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1007], edge_index=[2, 3944], x=[1007, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1136], edge_index=[2, 4222], x=[1136, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1063], edge_index=[2, 4152], x=[1063, 21], y=[32]) 32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[694], edge_index=[2, 2718], x=[694, 21], y=[24]) 24\n",
      "torch.Size([24, 21])\n"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    print(batch, batch.num_graphs) # Batch is column vector\n",
    "    x = scatter_mean(batch.x, batch.batch, dim=0)\n",
    "    print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://shapenet.cs.stanford.edu/media/shapenetcore_partanno_segmentation_benchmark_v0_normal.zip\n",
      "Extracting data/shapenetcore_partanno_segmentation_benchmark_v0_normal.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import ShapeNet\n",
    "\n",
    "dataset = ShapeNet(root='data', categories=['Airplane'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MessagePassing : Defines the aggregation to use (add,max,mean), direction of message passing  \n",
    "MessagePassing.propagate() : start of message passing  \n",
    "MessagePassing.message() : constructs the message(i:target or current node  j: neighbors)  \n",
    "MessagePassing.udpate() : updates node embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KIPF(GCN) Message Passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Add self-loops to the adjacency matrix.\n",
    "2. Linearly transform node feature matrix.\n",
    "3. Compute normalization coefficients.\n",
    "4. Normalize node features in 𝜙.\n",
    "5. Sum up neighboring node features (\"add\" aggregation).  \n",
    "1-3 before message passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5). Type of aggregation operation we want\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]     #(E,)\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        return self.propagate(edge_index, x=x, norm=norm)       # Internally calls message(), aggregate() and update()\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j                          # x_j neighboring node features of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0d2366846c94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Calling the message Passing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "#Calling the message Passing\n",
    "conv = GCNConv(16, 32)\n",
    "x = conv(x, edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For each node i calculated diff between ith node representationa and each of its neighbor node(j) representation\n",
    "2. Concat both node representations\n",
    "3. Pass concat representation through Linear-ReLU-Linear layers\n",
    "4. Max of all representation for each node i  \n",
    "Edge convolution is dynamic convolution that recomputes the graph for each layer using Nearest neighbor in feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EdgeConv(MessagePassing):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='max')\n",
    "        mlp = Seq(Linear(2*in_channels, out_channels),\n",
    "                 ReLU(),\n",
    "                 Linear(out_channels, out_channels))\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        self.propagate(edge_index, x=x)                 # x: (N, in_channels), edge_index: (2, E)\n",
    "        \n",
    "    def message(self, x_i, x_j):                        # x_i: (E, in_channels), x_j: (E, in_channels)\n",
    "        tmp = torch.cat([x_i, x_j - x_i],dim=1)         #tmp: (E, 2*in_channels)\n",
    "        return self.ml(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
